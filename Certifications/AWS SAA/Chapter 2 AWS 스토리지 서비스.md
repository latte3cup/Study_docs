### 스토리지 서비스의 3 유형
- 객체 스토리지 : 데이터+메타데이터+ 고유 ID를 구성으로 갖는 객체의 저장소
--> 빈번 수정/삭제에 불리. 실시간 업데이트 데이터에 부적합.
- 블록 스토리지: 데이터를 같은 크기의 블록으로 나누어 저장하고 각 블록의 고유 주소를 부여해 직접 접근하는 스토리지. EC2에서 자주 사용 (스냅샷) + EBS
- 파일 스토리지 : 우리가 흔히 아는, 파일 단위로 데이터를 저장하고 경로 기반 접근.

---- 

### S3 (Simple Stroage Service)
- 객체 스토리지
-  2006년 소개. 99.99999999999 (9가 11개) 수준의 내구성 및 고신뢰성
- 네임스페이스로 버켓 단위로 관리.
##### - 장점
- 간편성 : 진관적인 웹기반 콘솔 + 모바일 앱도 제공, 리눅스 스타일의 AWS CLI도 제공
- 확장성 : 거의 무제한 확장성 , (데이터 레이크)
- 신뢰성 : 99.99999999999 의 신로성으로 두개 시설의 문제가 생겨도 보존 (3개에 분할 저장)
- 보안성 : 암호화 기능 제공, 자동 암호화,  IAM에 따른 접근 권한 관리
- 고성능 : 네트워크 효율을 위한 멀티파트 업로드 기능 제공
- 가용성 : 99.99퍼센트의 요청 응답 성공. --> 일 : 8.6s / 주 : 1m 0.5s / 월 : 4m 23/ 연 : 52m 35
- 저비용 : 비용대비 높은 효율성. 사용량에 대해서만 지불 
- 관리 용이성 : 자동 스토리지 최적화, 보안 관리의 효율성 증대
- 연꼐성 : 다른 서드 파티 도구와 쉽게 연계

##### - 실무 활용법
- 데이터 백업 : 신뢰성이 높으므로 백업에 좋고, 버전별 관리 기능을 제공.
- 테이프 저장 장치 대체 
- **정적 웹사이트 호스팅** : 요청 처리 확장으로 쉽게 접속 가능
- 애플리케이션 호스팅 : 백엔드 없는 앱을 쉽게 배포
- 재난 복구 : 크로스 리전 복구 전략(미리 다른 리전 백업-복제도 쉬움)으로 쉽게 복구 및 사용
- 콘텐츠 배포 : 미디어 파일 등도 쉽게 접근 가능 및 소프트웨어 다운로드 창구로도 가능. Cloudfront로 직접 배포도 간으
- 데이터 레이크 :  어떠한 종류든 막대한 데이터를 저장 가능 및 다른 분석도구와 연계 가능
- 프라이빗 저장소 

##### - S3 기본 개념
-  URL
	 `http://버킷명.s3.리전.amazonaws.com/객체키`
- 버킷의 목적
	1.  S3 네임스페이스 최상위 레벨
	2. 비용 부담하는 계정의 표시
	3. 액세스 컨트롤에서 역할 수행
	4. 사용량 보고서 누적 유닛 표시
-  특징
	 기본적으로 다른 리전 반출 불가
	 객체마다 유일한 ID 할당
	 S3의 기본 인터페이스는 REST API , https 모드에서 **SOAP API** 지원
- S3 REST API 와 대응되는  HTTP 명령
	 GET -> Read/ POST ->Create / PUT-> Create / Delete -> delete
	 같은 객체 키에 PUT/POST 하면 덮어짐 , 즉 create

##### - 데이터 일관성 모델
- S3는 OS 기반 파일 시스템이 아닌 웹 기반의 데이터 저장소 
- 객체 작성 시 AZ 내 로드밸런서와 연결 -> 웹서버 API 연결 ->  인덱싱 및 스토리지에 중복 저장
- 기록 후 판독 일관성 및 종국적 일관성 모델을 제공
- 모든 AZ에 변경 사항이 적용 될떄까지 그 전의 형태로 제공. 3 AZ에 반영디 되야 다 제공
- 객체 잠금을 지원하지 않으므로 최종 PUT 된 데이터가 남음

##### - 성능 고려
- 초당 100회 이상의 PUT/LIST/DELETE 혹은 300회 이상의 GET 하는 경우 작업의 워크로드 분산  고려해야함
- 버킷은 자동으로 파티셔닝 해주며, 버킷 이름은 글로벌에서 유니크함.
- 객체 키는 버킷 내에서 유일 해야하며, 최대 1024 바이트 용량의 UTF-8 로 저장 (즉 이름이 1024바이트를 넘을 수 없음)
- 객체 키 경로 접두사에 따라 **트리 구조의 파티셔닝**을 진행.
-- 과거에는 경로 마다 접두어의 맨 앞 글자로 파티셔닝 트리를 형성했다고 한다.
-->  하지만 2018년 이후로 자동 샤딩 등에 의해 , 키 이름 문자열 역순 배열 혹은 Hex Hash 프리픽스 추가(무작위로 하여 잘 분산되게끔) 는 비권장 된다.

##### - 암호화
- 크게 2가지 - 전송 중 데이터 암호화, **저장된 데이터 암호화**
- 전송 중 데이터 암호화는 AWS의 특별한 기술이 아닌 TLS 및 https를 통한 종단간 암호화를 의미한다.
- **저장 시** 암호화 - 크게 클라이언트 측 암호화 , 서버 측 암호화로 나뉨
	1. 클라 측 암호화는 전송 전  암호화하는 방식.  (CSE)
		 이 경우 S3는 암호화된 파일을 바이너리 형태의 파일로 인식하므로 새로운 SSE를 명시적 지정하지 않는 한 암호화하지 않음. 
		 - **CSE**-KMS : 암호화는 클라에서 하지만 키는 kms에서 만듬
		 - **CSE-C** : Aws 클라이언트에 암호/복호 키를 지정해서 적용. 다만 KMS에 저장 X
	2. 평문 전송 후 S3/KMS 가 암호화하여 저장하는 방식
			이 경우 전송중 암호화로 평문이 암호화됨으로써 보안을 지키고 저장시에 암호화
		- SSE-S3(SSE-SE) : S3에서 관리하는 암호화 키로 암호화
		- SSE-KMS : S3에서 KMS를 사용하여 암호화
		- SSE-C : 자신이 작성 및 관리하는 암호화 키로 S3에서 암호화. 즉 이거도 요청 보낼떄 지정해야 S3에서 복호화하여 가져올 수 있음

##### - 접근성 통제  (액세스 컨트롤)
 3가지 방식이 있음 - **접근 정책 , 버킷 정책 , 접근 제어 목록**
1. 접근 정책
 - IAM으로 S3의 객체를 세분화해서 통제. ARN을 명시하여 권한 조정 (IAM에서 자세히)
 - 객체별 경로별 권한 접근 정책을 정했던거 생각하면 됨
 -  이건 주체 기반 정책 (Identity-based policy)
2. 버킷 정책
- S3 버킷 자체에서 권한 탭에서 적용 할 수 있음.  
-  외부 사용자나 다른 계정의 접근도 제어 가능한 정책
-  이건 리소스 기반 정책 
-  principal 속성으로 접근 통제
3. 접근 제어 목록 (Access Control List)
- ACL은 리소스 단위로 권한을 빠르게 부여할 수 있는 오래된 방식
- 레거시한 기능이며 세부 권한 통제가 부족하므로 지양 권장
- 리소스 기반 정책으로 분류됨

S3 보안 추천
- 최소한의 접근 권한 전략 사용 필요
- 다중인증 시스템 활용
- s3 버킷에 대한 감사 수행 - 정기적 , AWS Truested Advisor
- IAM role 활용하기

##### - S3 스토리지 클래스
- 스토리지 클래스간 이동이 가능
- 데이터 라이프 사이클 정책을 통해 클래스간 파일 이동도 가능
- 객체마다 스토리지 클래스를 적용할 수 있어 버킷은 여러 스토리지 클래스를 가질 수 있음
- 스토리지 클래스 변경은 물리적으로 데이터 저장 위치를 바꿈. 논리적으로는 동일한 경로를 유지

1. **Amazon S3 Standard :**  
 - 기본형 스토리지. **고신뢰성, 고가용성, 고성능** 제공
 - S3 SLA(Service Level Agreement, 서비스 수준 계약) 요건 충족
 - 전송/저장후에 대한 SSL 지원, 데이터 라이프 사이클 정책, 크로스 리전 복제, 이벤트 알림 제공
2. **Amazon S3 Standard IA (Infrequent Access)**
  - 스탠다드와 거의 비슷함. 다만 저장 요금은 더 싸고 조회 요금은 더 비쌈
  - 데이터 라이프 사이클을 통해 장기저장,백업,재해 복구 등 목적으로 활용
3. **Amazon S3 One Zone-IA**
 - 위와 거의 동일. 차이점은 S3는 원래 3개의 AZ에 중복 저장하는데,  이는 하나의  AZ에서 다중 중복 저장
 - 따라서 가용성은 99.5 로 낮음 (해당 AZ 장애시 가용불가)
4. Amazon S3  Intelligent-Tiering
 -  접근 빈도를 예측할 수 없는 데이터를 위한 스토리지 클래스
 - 사용자가 직접 고나리하지 않아도 스토리지 비용을 줄여줌
 - 자동 분석 수수료 + 각 티어별 저장/조회 비용을 과금
 -  티어 : Frequent - Infrequent - Archive Instant - Archive - Deep Archive
 5.  **Amazon S3 Glacier**
  - 데이터 아카이브용으로 사용
  - 3단계의 복원 옵션이 있음
 6. **Amazon S3 Glacier Deep archive**
  - 더 장기간 보관 선택용 - 자기 테이프 드라이브의 대체제 
  - 데이터 복원에 최대 12시간 소요

| 특징           | S3 Standard            | S3 Intelligent-Tiering | S3 Standard-IA         | S3 One Zone-IA         | S3 Glacier             | S3 Glacier Deep Archive |
| ------------ | ---------------------- | ---------------------- | ---------------------- | ---------------------- | ---------------------- | ----------------------- |
| 내구성          | 99.999999999% (11개의 9) | 99.999999999% (11개의 9) | 99.999999999% (11개의 9) | 99.999999999% (11개의 9) | 99.999999999% (11개의 9) | 99.999999999% (11개의 9)  |
| 가용성          | 99.99%                 | 99.99%                 | 99.9%                  | 99.5%                  | 99.99%                 | 99.99%                  |
| 가용성 SLA      | 99.9%                  | 99%                    | 99%                    | 99%                    | 99.9%                  | 99.9%                   |
| AZ           | 3                      | 3                      | 3                      | 1                      | 3                      | 3                       |
| 객체별 과금 최소 용량 | 없음                     | 없음                     | 128KB                  | 128KB                  | 40KB                   | 40KB                    |
| 과금 최소 저장 기간  | 없음                     | 30일                    | 30일                    | 30일                    | 90일                    | 180일                    |
| 인출 비용        | 없음                     | 없음                     | per GB retrieved       | per GB retrieved       | per GB retrieved       | per GB retrieved        |
| 전송 지연        | 밀리초                    | 밀리초                    | 밀리초                    | 밀리초                    | 수 분~수 시간               | 수 시간                    |
| 스토리지 타입      | 오브젝트                   | 오브젝트                   | 오브젝트                   | 오브젝트                   | 오브젝트                   | 오브젝트                    |
| 라이프사이클 전환    | 가능                     | 가능                     | 가능                     | 가능                     | 가능                     | 가능                      |

Amazon S3 RRS는 이제 사용 못함


##### 파일을 다른 스토리지 클래스로 이동 방법
- s3 라이브 사이클 정책 생성
- aws CLI에서 s3 복제 명령
- amazon 콘솔 활용
- aws sdk 사용

##### 객체 버전 관리
- 버저닝 활성화 시 같은 키를 업로드하면 새 객체가 새로운 버전으로 추가 
- S3가 내부적으로 버전 ID 생성하여 구분 및 관리
- Put으로 덮어써도 이전 버전으로 보존, Delete는 삭제 마커가 붙음
- 버저닝 한번 활성화하면 비활성화 불가능. 하지만 일시 정지 가능

##### - 객체 라이프 사이클 관리
- 라이프 사이클 매니지먼트 사용하면 편함
- 파일 이동 : 오직 시간의 흐름에 따른 객체 이동 규칙으로 관리
- 파일 삭제 : 설정한 시간 기준을 만조한 객체를 삭제
- 조건
	- **객체 생성(업로드) 후 N일 경과**
	- **비현재 버전 생성 후 N일 경과**
	- **삭제 마커 생성 후 N일 경과**

##### - S3 복제
- 하나의 버킷에서 다른 버킷으로 복제 (비동기적)
- 업로드 시점의 객체를 복사하는 일방향 프로세스임 (소스 -> 타겟)
- 복제는 버킷 전체 범위에 대한 복제 규칙을 정의하여 수행됨.  
- 복제는 두가지 유형
 1. CRR (Cross Region Replication) : 서로 다른 리전간 객체 복제
 2. SRR (Same Region Replication) : 같은 리전 내에서 객체 복제
- 복제 조건
	**버저닝이 활성화된 버킷에 새로 업로드된 객체**
	**Lifecycle 복제 규칙(Prefix 또는 Tag)에 일치하는 객체** 
	복제 설정 이후에 생성된 객체 (이전 객체는 복제 안 됨)
	삭제 마커나 이전 버전은 기본 복제 대상이 아님 (옵션 설정 필요)
	두 버킷의 ObjectLock설정이 동일
- RTC (Replication Time Control)는 15분내에 복제가 완료되도록 보장하는 SLA 옵션 (과금 옵션임)

##### S3 정적 웹사이트 호스팅
- index.html, error.html 지정하고 버킷 퍼블릭 접근을 허용하면 활성화 가능
- `http://<bucket-name>.s3-website-<region>.amazonaws.com` 으로 개방됨
- 이 S3 기능만으로는 https 불가

### 스토리지 서비스 상세
#### AWS S3 Glacier
- 자기 테이프 스토리지 대체 - 자기 테이프 방식의 관리 비용이 없고 신뢰성 수준도 높음
- 헬스케어/생명과학/과학 데이터 저장 - 의료 데이터등은 생성/이동/보관에 까다로운 규제 정책에 적합 등
- 하나의 파일마다 해당 파일에 대한 아카이브가 생성되므로 zip/tar로 압축한뒤 업로드하면 더 저렴함
	-  아카이브 는 1byte ~ 40TB , 업로드 개수 제한 없음. write-once 전략
	- 100MB 이상의 경우 멀티파트 업로드 추천 (단일 최대 4GB)
	- 아카이브는 데이터 금고 역할을 수행하는 볼트(Vault)에 저장 - 리전당 1000개 볼트
	-  볼트는 일반 S3의 버킷과 같음
	- 볼트 인벤토리라 불리는 아카이브 인덱스는 24시간 마다 갱신
	- 아카이브 복구를 위해선 아카이브 아이디를 알아야하는데 토큰 처럼 발급만 하고 관리안하므로 사용자가 관리해야함.
	- Retrieval Job 을 통해 Standard/Expedited/Bulk 로 복원

 ---> 이건 레거시 볼트만 이용하는 경우에 해당함
 현재에는 볼트 (glacier)가 S3에 통합된 형태이고 S3로 관리하면 객체키로 관리하므로 더 관리가 편하고 용이해서 보통 S3 씀

| 항목         | 레거시 Vault 기반            | 📌 S3 Glacier(Storage Class)                     |
| ---------- | ----------------------- | ------------------------------------------------ |
| 저장 단위      | Vault → Archive         | S3 버킷 → 객체(Key)                                  |
| 저장 클래스     | 없음 (Glacier 자체)         | STANDARD / GLACIER / GLACIER_IR / DEEP_ARCHIVE 등 |
| 객체 이름      | ❌ Archive ID만 존재        | ✅ Key (ex: `logs/2024/04.tar.gz`)                |
| 저장 크기      | 1B~40TB                 | 동일                                               |
| 멀티파트 업로드   | 전용 Glacier API로 직접 처리   | ✅ S3 멀티파트 방식 그대로 사용                              |
| 버전 관리      | ❌ 불가                    | ✅ 가능 (S3 버전 관리 활용)                               |
| 메타데이터      | ❌ 없음                    | ✅ S3 메타데이터, 태그 등 활용 가능                           |
| 아카이브 수     | 제한 없음                   | 동일 (S3 객체 수와 동일 기준)                              |
| Vault      | ✅ 필요                    | ❌ 없음                                             |
| 복원 방식      | Retrieval Job           | ✅ `RestoreObject` API (Key 기반)                   |
| 복원 대상      | Archive ID              | ✅ Key                                            |
| 복원 지연      | Expedited/Standard/Bulk | 동일 (단, 호출 방식 다름)                                 |
| 복원 상태 추적   | `describe-job`          | ✅ `head-object`로 복원 여부 확인                        |
| Inventory  | ✅ Vault Inventory Job   | ❌ 필요 없음 (객체 목록 조회 가능)                            |
| Archive ID | ❗사용자가 직접 관리             | ❌ 필요 없음 (Key로만 접근)                               |
| Lock       | Vault Lock              | S3 Object Lock                                   |
참고 : <https://insufficientlyadvanced.tech/posts/2021/glacier-deprecation/>

----

#### Amazon Elastic Block Store
-  EC2 인스턴스를 위한 영구 스토리지. 즉 EC2 수명에 상관없이 존재
- 네트워크에 부착되어 사용됨. 
- EC2 를 실행하기 위한 부트 볼륨임 , (그냥 D하드처럼 위한 EBS를 붙일수도 있음)
- 기본적으로 한 순간에는 하나의 EC2 - 하나의 EBS  (귀속 아님) 
- 예외로 EBS Multi-Attach (io1, io2 전용)을 사용해 여러 EC2에 하나 EBS 가능하나 까다로움
- 오직 같은 AZ 내에서만 탈부착 가능
- Ec2 로컬 스토리지보다는 높은 가용성
- 연간실패율 AFR: Annualized failure rate 은 0.1~0.2 퍼 수준
- 종류 
  1. Amazon Ec2 인스턴스 스토어
  2. Amazon EBS SSD-기반 볼륨 : DB 및 부트 볼륨을 위함
  3. Amazon EBS HDD-기반 볼륨 : 로그 처리 및 맵리듀스와 같은 처리 성능에 집중
###### EC2 인스턴스 스토어
- Ec2 실행시 하나씩 포함되는 자동 스토리지 EC2타입에 따라 하드 종류도 달라짐
- 사용자가 타입 결정할 수 없음. 

- 볼륨 상세 종류
 1. Amazon EBS Elastic Volume :  동적 용량 증대, 성능 튜닝/성능 저하 없이 볼륨 변경
 2. Amazon EBS-SSD Volume : 범용 SSD(gp2), 프로비전 IOPS SSD(io1)로 구분
   - IOPS(Input/Output Operations Per Second) : 초당 입출력 처리 횟수
   - gp2는  iops가 정해져 있으면 성능과 비용을 균형적으로 유지, io1 (최신 io2)는 사용자가 직접 IOPS를 지정할 수 있으며 고성능 중심, 해당 비용이 분리되어 있음.
   - 보통  HDD - 7200RPM : ~100 IOPS , SSD SATA : 대충 ~50000 IOPS (편차가 큼) - 훨빠름
   - gp2는 약 100~ 16000 IOPS (용량에 따라 비례하지만 제한이 16000) - 용량이커지면 병렬성 증가로 IOPS도 비례
   - 1기가 용량당 약 3 IOPS의 증가함. gp2는 16TB이지만 5334기가 부터 16000 IOPS로 제한
   - 1TB 이하는 보통 버스트 버킷(burst Bucket) 기능 사용 가능 : 사용한한 IOPS는 크레딧 킵되고 성수기에 사용됨. 
   - io1는  ~64000 IOPS까지 가능 비율은 1:50  , io2는 ~256000 1:500
  1. Amazon EBS-HDD 볼륨 
   - 높은 빈도 입출력 및 처리 성능 최적화 HDD : (st1)
   - 낮은 빈도 입출력 및 비용 절감형 **콜드 HDD** : (sc1)