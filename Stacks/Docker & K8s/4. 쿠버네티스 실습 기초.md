- 네임스페이스는 쿠버네티스 리소스를 논리적으로 격리하고 관리하기 위한 가상 공간이다.
- YAML <-> json 은 완벽 호환되므로 리소스 정의에도 문제없음.
### 포드 실행
1. 포드 실행은 run 명령으로 실행됨. -->  빌드한 이미지나 이미지를 Pull해서 가져옴
2. 아니면 Manifest (yaml 파일로 생성하여 실행 가능)

### 디플로이먼트(Deployment)
: 쿠버네티스를 구성하는 핵심 개념 중 하나
###### 개념
- 디플로이먼트는 포드를 관리하기 위한 개념
- 하지만 먼저 레플리카셋을 알아야함 (Replicaset)
- 레플리카셋은 명시되어 있고 유지해야하는 파드 개수에 대한 **가용성을 보증**하는 데 사용
- 즉, 디플로이먼트는 레플리카셋을 관리하는 컨트롤러이다.

###### 실행
1.  kubectl create deployment deploy-hello -image = hello-world --replicas = n
--> 여기서 특정 포드를 지우면 다시 n 지정한 만큼 유지되도록 포드가 다시 생성됨
--> 따라서 디플로이먼틀르 지워야 관련된 포드를 깔끔히 지울 수 있음
2. 디플로이먼트도 동일하게 Mainfest를 통해 실행할 수 있다.
###### 스케일링
- 다시 apply를 통해 변경된 설정으로 적용할 수 있다. yml 이 아니라면 set 명령을 통해 적용함
- 여기서 말하는 스케일링은 스케일 아웃, 포드의 수를 변경하는 것이다.
- 이 스케일링은 레플리카셋의 변경사항에 기록되지 않는다.
- 즉 스케일링은 롤아웃을 일으키지 않는다.
###### 리비전 (변경사항 관리)
- 롤백 : 되돌림 ㅇㅇ
- 하지만 조금 생소한 개념인 롤아웃(Rollout)을 알아야함
--> 롤아웃 : 쿠버네티스 Deployment에서 새로운 버전(Pod Template)을 기존 버전으로부터 점진적으로 교체하는 프로세스
--> Rollout은 오직 `spec.template`이 변경될 때만 일어난다. (spec은  포드의 실제 구성 내용)
--> 롤아웃은 기존 레플리카셋의 포드를 점차 줄이고 새로운 레플리카셋의 포드를 점차 변경하여 늘리면서 교체

### 서비스
:  클라이언트와 파드의 연결을 담당
###### 개념
: 포드는 쿠버네티스에서 일시적인 존재로 언젠가는 정지됨. 포드가 클라이언트에게 서비스를 제공하려면 클라이언트는 포드의 IP 주소를 요청해야함.
: 하지만 포드별 ip 주소가 다르고 , 포드가 죽고 탄생함으로써 ip 주소는 매번 변경됨.
: 따라서 하나의 서비스로 **논리적인 포드의 집합을 정의**하고 **클라이언트가 그 포드에 접근할 정책을 정의**하는 추상적 개념 --> 즉 외부 트래픽 노출, 로드 밸런싱 및 파드들에 대한 서비스 디스커버리를 가능하게 함

#### 서비스 종류
1. ClusterIp : 서비스의 기본 설정 값으로서 클러스터 내에서만 파드에 접근될수 있도록 하는 유형

2. NodePort : 각 노드의 특정 포트를 통해 외부 접근을 제공하는 유형. NAT을 사용하는 클러스터 내에서 각 노드들의 지정된 포트 (30000~32767)을 외부에 노출 **\<NodeIP>:\<NodePORT>**\\ 를 이용해 접근하게 함.  ClusterIP의 상위 집합이기도 함
--> 외부에서 해당 서비스에 접근하려면 위에 써있듯이 해당 노드의 IP & port를 알아야함

3. LoadBalancer : 외부용 로드밸런서를 생성하고 서비스에 고정된 공인 IP 를 할당
--> IP & Port 를 이용해 클러스터 외부에서 서비스에 접근. NodePort의 상위 집합
--> NodePort의 상위 집합이지만 공인 IP 및 포트 하나를 노출하므로 NodePort는 알 필요 없음
--> 기본적으로 이 서비스를 작성 한다고 해도 외부에서 해당 IP에 접근할 수 없음. 

4. ExternalName : CNAME(Canonical) 레코드를 통해 클러스터 외부 서비스로의 DNS 조회를 제공하는 유형. 즉 클러스터 외부에 있는 외부 도메인을 가리키도록 설정 가능
--> 이는 내부에서 외부의 리소스를 내부처럼 사용하기 위해 사용.
--> 이는 위 3개와 완전 독립적으로, 셀렉터도 없고, 포드도 생성되지 않음
--> 또 이는 논리적이므로, 물리적으로는 API-서버 내부에 존재. 즉 마스터 노드 리소스에 물리적 위치.


### 스토리지 볼륨
: 도커와 동일하게 컨테이너 생명 주기에 따라 내부의 파일도 생성 및 삭제됨. 
--> 따라서 파드가 재실행 되더라도 보존할 스토리지를 제공
: 그리고 기본적으로 포드 생성 시 디폴트 볼륨은 하나가 무조건 생성 되는데, 이떄 타입은 projected (복합) 볼륨 으로 이하의 것들을 포함 하고 있다.

| 파일          | 설명             | 주요 용도        |     |
| ----------- | -------------- | ------------ | --- |
| `token`     | API 접근용 JWT 토큰 | 인증           |     |
| `ca.crt`    | API 서버 CA 인증서  | TLS 검증       |     |
| `namespace` | Pod의 네임스페이스 이름 | API URL 구성 등 |     |

그렇다면 보통 명시적으로 지정하는 볼륨들은 ... (더 많긴함)
1. emptyDir : 파드 내부에서 임시적으로 사용하는 볼륨
2. hostPath : 노드 내에서 데이터를 저장할 수 있는 볼륨
3. PersistentVolume : 외부 서버에 데이터를 저장하는 볼륨

##### emptyDir
- 포드 내부에서 임시적으로 사용. -> 즉 컨테이너가 아닌 포드 내부라 포드 내부의 컨테이너끼리 같은 볼륨을 이용 가능.
 - 포드의 emptydir과 컨테이너 내부의 파일 경로롤 바인딩 함으로써 컨테이너마다 마운트 경로가 달라도 동일한 디렉토리를 공유함 (포드 입장)

##### hostpath
: 호스트 노드의 파일 시스템의 경로와 포드의 경로와 바인딩 하는 것
- 즉 다른 파드라도 노드가 동일하면 데이터가 통신 및 유지 가능
- 하지만 노드 자체에 장애가 생기면 데이터를 유실하게 되는 단점도 있음
- 그리고 보안문제가 있어서 가급적 비권장함.
- 왜나하면 노드 로컬 파일 시스템의 중요한 시스템 경로와 마운트하면 파드에서 파일을 건들 수 있음
- 그래서 꼭 써야한다면, 파일 혹은 디렉토리에 ReadOnly만 적용하여 사용 하는 것을 권장
- 해당 포드가 내려가도 로컬 파일 시스템과 바인딩 되었으니 당연히 파일이 유지됨.

##### PV(PersistentVolume)
: 외부 스토리지와 연결. 이를 사용하려면 PVC: PersistentVolumeClaim을 이용해야함.
- PV는 스토리지 자원을 의미하면 PVC는 스토리지를 동적으로 바인딩하기 위한 요청 객체를 의미.
- 즉, 쿠버네티스 클러스터 관리자가 PV를 생성하고, 사용자가 PVC를 통해 PV를 요청



PV 실습 
1. 모든 노드에 nfs-common (Network File System) 를 설치해야함
2. nfs 서버를 위치할 곳에 nfs-server 설치
3. nfs 서버 파일 시스템의  /etc/exports에서 공유할 디렉토리와 허용할 ip를 작성
4. pv, pvc, pod 작성 -> Pod <--> pvc , pvc <--> pv 되도록 작성함
5. 실행하면 nfs 서버를 설치한 곳에 잘 있음

| AccessMode 값          | 의미                 | 설명                                  |
| --------------------- | ------------------ | ----------------------------------- |
| `ReadWriteOnce` (RWO) | 단일 노드에서 Read/Write | ❗ 여러 Pod에서 동시에 사용 불가 (노드 1개만 접근 가능) |
| `ReadOnlyMany` (ROX)  | 여러 노드에서 Read Only  | 🔍 로그 공유 등 읽기 전용 공유                 |
| `ReadWriteMany` (RWX) | 여러 노드에서 Read/Write | ✅ 공유 스토리지, 협업 처리 가능                 |

### 스테이트풀셋 (StatefulSet)
: 디플로이먼트와 비슷. 즉, 무상태성인 디플로이먼트는 언제든 파드가 다른 파드로 대체될 수 있음.
- 하지만 스테이트풀셋은 상태를 가지므로 각 파드마다 **영구적인 식별자**가 부여되고 **독자성**이 부여됨.
- 이를 사용하는 이유는 분산 시스템의 구성이다. 
- 영구적인 식별자가 규칙을 가지므로 사용자는 보다 쉽게 분산환경을 구성 가능
- 스테이트 풀셋은 PVC는 자동으로 바인딩해주지만 이에 따른 PV는 수동으로 해야하므로 보통 툴을 쓰거나 StorageClass를 통한 동적 바인딩을 사용한다.
- 동적 바인딩에 Rook 프로그램을 추천
##### 헤드리스 서비스
: 각 파드들의 개별 네트워크를 식별하기 위해 필요한 서비스 --> ClusterIP가 없음.
: 각 파드가 고유한 DNS 주소를 갖도록 함.

- 스테이트풀셋을 사용하기 위해서 반드시 헤드리스 서비스가 필요한 것은 아니다. --> 물론 이 경우 파드 생성의 순서가 있고, PVC가 자동으로 붙은 디플로이먼트에 불과하다.
- 이렇게 되면  포드끼리 DNS로 인한 접속이 가능함.  -->(Kube-system 네임스페이스의 coreDns가 DNS 정보를 저장함)
-  -->curl \<pod-name>.\<service-name>.\<namespace>.svc.cluster.local
-  만약 다른 네임스페이스에 존재하는 포드가 해당 DNS로 접속하려면 해당 네임스페이스에 대한 DNS 수신을 오픈해야함


### 인그레스
: 클러스터 외부에서 내부에 존재하는 쿠버네티스 서비스에 접근하기 위해 HTTP/HTTPS를 활용한 라우팅 규칙을 제공하는 오브젝트
- 클러스터 내부에 존재하는 여러 서비스를 LoadBalancer 없이 외부에 노출시킬때 유용하게 사용
- HTTP임므로 URL 기준으로 라우팅
##### 헬름
: 인그레스를 설정하고 배포하는 도구 
- 헬름 차트 : 쿠버네티스 리소스를 생성하기 위해 필요한 파일을 모아놓은 디렉토리이다.
- 헬름 템플릿인 values.yaml을 이용하면 설치에 필요한 여러 변수를 한번에 설정할 수 있고, 쿠버네티스 리소스를 최적화하기에도 쉬움
- 헬름 리포지토리는 다양한 헬름 차트를 저장 및 공유하는 장소 ( 외부 공식 서버임 ㅇㅇ)

Bitnami는 오픈소스 애플리케이션을 Docker Image, Helm Chart, VM, Cloud Image 등 다양한 형태로 패키징해서 배포하는 회사이자 프로젝트다.
