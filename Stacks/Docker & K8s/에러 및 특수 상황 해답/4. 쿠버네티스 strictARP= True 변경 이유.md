#### 상황
metalLB 설치 및 설정에 관한 부분.
 kubectl get configmap kube-proxy -n kube-system -o yaml | grep strictARP
 strictARP = false 가 기본값으로 되어 있는 것을 알 수 있음

#### 결론
**MetalLB의 L2 모드는 “IP의 소유권”을 ARP로 네트워크에 광고하는 방식인데**,  
kube-proxy의 IPVS 모드에서 `strictARP: false`면  
**모든 노드가 그 VIP(가상 IP)에 대해 ARP 응답할 수 있는 상태가 되어버려서**,  
결과적으로 **트래픽이 엉뚱한 노드로 가거나, 클러스터 전체가 IP 충돌을 일으키게 된다.**
  

#### 정리
##### 1. MetalLB의 L2 모드
- 외부에서 LoadBalancer IP로 요청이 오면
- MetalLB Speaker가 **"이 IP는 나야"** 하고 ARP 응답을 함
- 그래서 트래픽이 해당 노드의 MAC으로 도달
##### 2. kube-proxy의 IPVS 모드
- VIP(서비스 IP)를 커널 가상 인터페이스에 바인딩
- 기본 설정(`strictARP: false`)이면 **모든 노드가 해당 VIP에 대한 ARP 응답을 허용**
- 이건 내부 클러스터 통신엔 문제 없지만, **외부 ARP 요청에 대한 충돌을 일으킬 수 있음**
---
###### 문제 시나리오 (`strictARP: false`)
1. MetalLB Speaker는 노드 A에서 "192.168.0.240은 나야"라고 ARP 응답
2. 그런데 **노드 B**도 IPVS가 해당 VIP를 알고 있고, **ARP에 응답해버림**
3. 스위치/라우터는 MAC 테이블을 보고 트래픽을 **노드 B로 보냄**
4. 노드 B는 그 VIP를 실제로 처리할 의도가 없으니 → **DROP**
→ 결과:  
❌ 접속 안 됨  
❌ 간헐적인 연결 실패  
❌ 클러스터 불안정


다시 정리하자면,

	클러스터 외부에서 VIP로 들어오는 요청은 MetalLB가 ‘입구’에서 트래픽 제어를 담당하므로, 
	그 VIP에 대해서는 MetalLB가 활성화된 노드만 ARP 응답을 하도록 설정해야 한다.  
	이를 위해 kube-proxy의 `strictARP: true` 설정이 필수다.